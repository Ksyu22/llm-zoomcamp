# Module Outline: Vector Search

### Theory

1. **Embeddings**:
    - Vector representation of text (other types of data). It's a way to translate textual representation into numerical one and allows to use this data with ML/DL algorithms.
    - Can be created with different embeddings model(word, sentence, document,...)

2. **Vector DataBase**:
    - Indexes and stores embeddings in a very optimal way which permits a very effective search
    - Allows to perform similarity search btwn elements
    - Can support LLMs with additional and easily available knowledge that LLMs might lack

  ***Indexing Embeddings***:
      Index our documents or some fields with embeddings and after perform query with vector representation for search.

  ***Vector DataBase Search***:
      Vector embedding search permits to improve search relevance because it captures semantic meaning, which is not available with usual keyword search.


3. **Offline Evaluation of Retrieval**:
    - Methods for evaluating the effectiveness of retrieval systems.
    - Metrics for assessing retrieval performance (e.g., precision, recall, F1-score).
    - Setting up offline evaluation experiments to benchmark retrieval systems.

### Practice

#### 1. [**Vector Search with Elasticsearch**](https://github.com/Ksyu22/llm-zoomcamp/blob/main/03-vector-search/elastic_search.ipynb):
   - Introduction to Elasticsearch and its capabilities for handling vector search.
   - Configuring Elasticsearch for embedding-based search.
   - Querying and retrieving documents using vector search in Elasticsearch.

#### 2. **Offline Evaluation of Retrieval**:

##### 2.1 Generation of the **ground truth** dataset on the basis of the actual records from our knowledge database.

**Strategy:** For every record(user question in FAQ) we are prompting gpt-4o-mini to generate similar/relevant records(questions). Every newly generated query is assigned with index that will help to reference original query when evaluating the quality of search mechanism.

**Challenges:**
- During this data preprocessing we had to deal with different possible unique indexes generation approaches (record indexes were not initially retrieved) in order to be able to build a lookup table for our evaluation task.
- Some records didn't get any relevant questions generated by LLM. Instead we got `question` value. These records were deleted from the ground truth dataset.

##### 2.2 Evaluation of retrieval

**Strategy:** For every generated question in Ground Truth dataset we will perform a search. The output will be compared with the original query answer and will allow us to compute the quality of our retrieval system.

###### 2.2.1 Metrics

###### 2.2.1.1 Hit Rate:

Is a metric that measures the fraction of queries for which the correct/relevant item is retrieved within the top *k* results. It answers the question: "How often does the system return a relevant result within the top *k* positions?".
Higher Hit Rate values indicate better performance.

###### 2.2.1.2 Mean Reciprocal Rank (MRR)

Is a metric that measures the average of the reciprocal ranks of the first relevant item for a set of queries. It focuses on the rank position of the first relevant result. MRR values range from 0 to 1, with 1 being the best possible score.

###### 2.2.2 Evaluation of search methods

For both we were using ElasticSearch
1. [Text search](https://github.com/Ksyu22/llm-zoomcamp/blob/main/03-vector-search/02_evaluation_text_retrieval.ipynb)
2. [Vector search](https://github.com/Ksyu22/llm-zoomcamp/blob/main/03-vector-search/03_evaluation_vector_retrieval.ipynb)
  - query vector field
  - text vector field
  - query+text vector field
  - combining the search on 3 vectors

**Results**

| Search            | Hit rate    | MRR      | it/s
|-------------------|------------------------|--------|
| Text              | 0.75        | 0.61     | 272.85 |
| V query           | 0.77        | 0.66     | 47.81  |
| V text            | 0.82        | 0.70     | 56.59  |
| V query+text      | 0.91        | 0.82     | 52.04  |
| V 3 vectors       | 0.90        | 0.80     | 42.53  |
