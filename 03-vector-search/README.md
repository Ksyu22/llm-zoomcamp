# Module Outline: Vector Search

### Theory

1. **Embeddings**:
    - Vector representation of text (other types of data). It's a way to translate textual representation into numerical one and allows to use this data with ML/DL algorithms.

2. **Vector DataBase**:
    - Indexes and stores embeddings in a very optimal way which permits a very effective search
    - Allows perform similarity search btwn elements
    - Can support LLMs with additional and easily available knowledge that LLMs might lack

  2.1. **Vector DataBase Search**:

  2.2. **Creating and Indexing Embeddings**:
    - Explanation of embeddings and their role in representing text as vectors.
    - Methods for generating embeddings using various techniques (e.g., Word2Vec, BERT, etc.).
    - Process of indexing embeddings to enable efficient search and retrieval.

3. **Offline Evaluation of Retrieval**:
    - Methods for evaluating the effectiveness of retrieval systems.
    - Metrics for assessing retrieval performance (e.g., precision, recall, F1-score).
    - Setting up offline evaluation experiments to benchmark retrieval systems.

### Practice

1. **Vector Search**:
   - _To be filled with practical exercises and code samples._

2. **Creating and Indexing Embeddings**:
   - _To be filled with practical exercises and code samples._

3. **Vector Search with Elasticsearch**:
   - Introduction to Elasticsearch and its capabilities for handling vector search.
   - Configuring Elasticsearch for embedding-based search.
   - Querying and retrieving documents using vector search in Elasticsearch.

4. **Offline Evaluation of Retrieval**:
   - _To be filled with practical exercises and code samples._



Vector DataBase :

indexes and stores vector embedding for optimal storage and search

Provides the ability to compare multiple things (semantically)

Can serve LLMs to become smarter and better recall pas data.

Performed Semantic search
